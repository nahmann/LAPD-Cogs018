{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project (change this to your project's title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions\n",
    "\n",
    "Place an `X` in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that student names will be included (but PIDs will be scraped from any groups who include their PIDs).\n",
    "\n",
    "* [  ] YES - make available\n",
    "* [  ] NO - keep private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project aims to shine light on the issues of crime rate in Los Angeles county and explores its relationship with the locations of police stations. By utilizing the data of crime records collected by the LA Police Department from 2010-present combined with current locations of LAPD police stations, we attempted a geographic data analysis and discovered trends in crime types and the locations associated with it. We found that [signficant founding from geopandas EDA here]\n",
    "\n",
    "Furthermore, we performed clustering algorithms that propose alternative/new locations for police stations around the county to more effectively distribute station locations. [Talk about kmeans not being able to evenly distribute crime to stations?] Through this we conclude that [TBD]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "- Nathan Ahmann\n",
    "- Alex Guan\n",
    "- Alan Miyazaki\n",
    "- Renaldy Herlim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does crime happen more or less frequently around police stations and can that knowledge be used to more effectively distribute police station locations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='background'></a>\n",
    "\n",
    "## Background & Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los Angeles has solidified itself as a historic city in America, with positive connotations such as art and film, along with negative ones such as crime rate. The latter has especially had an impact on the culture surrounding the city, as policing of the area has only grown to be more controversial. The city has observed a wide variety of crimes, ranging from petty theft to mass shootings. Due to how controversial the policing of the country has been, especially with the increasing prevalence of movements like BLM, Los Angeles has had the effectiveness of its law enforcement questioned. NPR discusses this topic during Planet Money: \"When You Add More Police To A City, What Happens?\"[^NPR], which explores how effective mass policing is for cities with varying levels of crime. Economists appear to have evidence that increasing the police force for the average city helps to prevent crime overall, but this is not observed in certain areas with a larger Black population. While there is an increase in arrests for lower level crimes, it seems that the homicide rate is effectively left unchanged. The article points to areas in the South and Midwest with this description, so our group wanted to consider the West Coast and specifically Los Angeles.\n",
    "\n",
    "The Violence Project[^Violence] takes a comprehensive look at mass shootings from around the country in the past sixty years, with a total of 187 up to March 2021. The database contains over 200 different variables to preview, allowing someone to explore motivations, weapons, background, etc. The website directly provides the ability to filter through the list of shooters, and additionally contains statistics on how prevalent they are in the data. This project in particular is focused exclusively on mass shootings and contains less than 200 rows of data (thankfully), so we decided to expand our project to all forms of crime within LA county.\n",
    "\n",
    "With all of the former in mind, we settled on investigating how the proximity of police stations may impact the crime in certain parts of Los Angeles. A common train of thought is that less crime would happen around police stations because they would act as deterents against crime. One related study found that crime rate increased around areas where a police station closed [^blesse]. They suggested that this supported previous papers claiming that more police stations are effective at detering crime, but that the measurement of deterence is hard to calculate. Another paper found more some actual numbers, stating that police stations in Buenos Aires created a 500-600m zone of decreased crime [^fondevila]. This is more in line with what we would like to investigate. By considering location data, we can see if police station prescene has any effects on the number of crimes or on the types of crimes commited.\n",
    "\n",
    "[^blesse] Blesse, S., &amp; Diegmann, A. (2022). The place-based effects of police stations on crime: Evidence from station closures. Journal of Public Economics, 207, 104605. https://doi.org/10.1016/j.jpubeco.2022.104605 \n",
    "\n",
    "[^fondevila] Fondevila, G., Vilalta-Perdomo, C., Galindo PÃ©rez, M. C., &amp; Cafferata, F. G. (2021). Crime deterrent effect of police stations. Applied Geography, 134, 102518. https://doi.org/10.1016/j.apgeog.2021.102518 \n",
    "\n",
    "[^NPR] Rosalsky, G. (2021, April 20). When you add more police to a city, what happens? NPR. Retrieved March 5, 2023, from https://www.npr.org/sections/money/2021/04/20/988769793/when-you-add-more-police-to-a-city-what-happens \n",
    "\n",
    "[^Violence] Most comprehensive mass shooter database. The Violence Project. (2023, January 31). Retrieved March 5, 2023, from https://www.theviolenceproject.org/mass-shooter-database/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We believe that less crime will happen closer to police stations which would imply that the presence of a police station deters crime. If criminal activity happens less around police stations then it would be important to effectively spread out police stations in order to minimize crime rate as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets 1-4 are from the official LA City database and geohub.\n",
    "\n",
    "### Dataset 1: Los Angeles Crime Data from 2020 to Present (March 1st 2023)  \n",
    "[Link to dataset 1](https://data.lacity.org/Public-Safety/Crime-Data-from-2020-to-Present/2nrs-mtv8)   \n",
    "  \n",
    "Number of observations: 673,367 \n",
    "This dataset includes information on crimes that took place in Los Angeles between 2020 and March 1st 2023.\n",
    "Since Dataset 2 and 3 have the same columns, the row information and relevant column is below.\n",
    "\n",
    "### Dataset 2: Los Angeles Crime Data from 2010 to 2019\n",
    "[Link to dataset 2](https://data.lacity.org/Public-Safety/Crime-Data-from-2010-to-2019/63jg-8b9z)  \n",
    "  \n",
    "Number of observations: 2,119,797 \n",
    "This dataset includes information on crimes that took place in Los Angeles between 2010 and 2019.  \n",
    "\n",
    "Each row represents a single crime that took place.\n",
    "The relevant columns are:\n",
    "* DR_NO - Divisions of Records number. Acts as an unique ID for the crime\n",
    "* DATE_OCC - The date that the crime occured\n",
    "* AREA - contains the geographic area code for the police station. These are 1-21 and correspond to 1 of the 21 police stations.\n",
    "* Crm Cd Desc - description of the criminal code. Essentially a human readable crime category\n",
    "* LOCATION - street address the crime took place at\n",
    "* LAT, LONG - latitude and longitude\n",
    "\n",
    "### Dataset 3/4: Los Angeles Police Station Locations and Division Shapes\n",
    "These datasets are geographical information. Dataset 3 contains info we used mainly to get the LONG/LAT of each police station, and Dataset 4 contains shape files used for plotting. We also made use of the area metric from Dataset 4 for some calculated fields. \n",
    "\n",
    "[Link to dataset 3](https://geohub.lacity.org/datasets/lapd-police-stations)   \n",
    "Number of observations: 21\n",
    "This dataset contains information on all 21 of LA City's Police Stations. If we find that our crime data extends past the city or want a more precise location, then we might make use of the extended data for LA county that includes more Police Stations and additioanlly includes Sheriff stations.\n",
    "\n",
    "Each row of the dataset contains information for one police station.  \n",
    "The relevant columns are:\n",
    "* DIVISION - the division the police station is under\n",
    "* LOCATION - an address for the police station. Since we would rather have a more precise location we might convert these to latitude/longitude or use the alternative dataset.\n",
    "* PREC - the precinct each station is in charge of \n",
    "\n",
    "[Link to dataset 4](https://geohub.lacity.org/datasets/031d488e158144d0b3aecaa9c888b7b3_0/explore?location=33.985210%2C-118.389876%2C11.32)  \n",
    "Number of observations: 21\n",
    "This dataset contains information on all 21 of LA City's Police Stations. If we find that our crime data extends past the city or want a more precise location, then we might make use of the extended data for LA county that includes more Police Stations and additioanlly includes Sheriff stations.\n",
    "\n",
    "Each row of the dataset contains information for one precinct.  \n",
    "The relevant columns are:\n",
    "* APREC and PREC - the division and number of the precinct\n",
    "* AREA - the size of the shape generated by the polygon (not sure what units, but consistent across shapes so comparable)\n",
    "\n",
    "### Dataset 5: City-Owned Properties in LA County\n",
    "Number of observations: 1810\n",
    "This dataset contains geographic locations and metadata on public city-owned properties. We used this dataset to perform the ArcGIS Maximize Coverage method by assigning these properties as potential new police stations.\n",
    "\n",
    "Each row contains information on:\n",
    "* The type of building/property (open land, warehouse, parking facility, etc)\n",
    "* Info on availability of use (Owned, Leased, etc.)\n",
    "* Location - Latitude and Longitude of the building, county \n",
    "\n",
    "[Link to dataset 5](https://geohub.lacity.org/datasets/lahub::city-owned-property-2/about)\n",
    "\n",
    "### Dataset 6: New Station Locations & Associated Demand Points\n",
    "[Link to dataset 6](https://drive.google.com/drive/u/1/folders/1QIxdKjOyTN1l5dmFSP-ZkjCdpaUfANCv)\n",
    "\"new_maximized_stations.csv\" and \"crime_demand_points.csv\"\n",
    "\n",
    "The cleaned version of the dataset is in a CSV format in our Google Drive\n",
    "\n",
    "This dataset is the output of the locations selected from Dataset 5 (City-Owned Properties in LA County). There are two CSV files associated with this dataset that are connected to each other, the first contains the coordinates of the new police stations and the second contains the location coordinates of when the crime occurs and what police station that crime is assigned to.\n",
    "\n",
    "\n",
    "### Combining the Datasets\n",
    "Dataset 1 and 2 contain our crime data. Due to coming from the same source, they are quite easy to combine and contain the same columns so we can simply concatenate them together (aside from a typo in one of them).\n",
    "\n",
    "\n",
    "Dataset 3 and 4 are used for geographical data, specifically LONG/LAT of police stations and the shape of each precinct. Combining them is simple due to the LONG/LAT being a universal metric. Additionally the precinct numbers correctly match up. Both of those metrics not only allow them to be used with each other but also with Dataset 1 and 2.\n",
    "\n",
    "Dataset 5 and 6 is used solely for ArcGIS analysis combined with Datasets 1-4 to perform duties such as analyzing heatmaps of crimes, driving coverage of current police stations and the new stations generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the two crime datasets were from the same organization (LAPD), the two sets were really easy to combine. The only change that needed to be done was that the dataset from 2010-2019 had a space in column name for Area while the dataset for 2020-present did not. Aside from this, all other columns were the same and the datasets were easily combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading datasets from two different time periods\n",
    "\n",
    "# https://data.lacity.org/Public-Safety/Crime-Data-from-2010-to-2019/63jg-8b9z\n",
    "past_df = pd.read_csv(\"Crime_Data_from_2010_to_2019.csv\", dtype = {\"TIME OCC\": str})\n",
    "# https://data.lacity.org/Public-Safety/Crime-Data-from-2020-to-Present/2nrs-mtv8\n",
    "present_df = pd.read_csv(\"Crime_Data_from_2020_to_Present.csv\", dtype = {\"TIME OCC\": str})\n",
    "\n",
    "LAPD_df = pd.read_csv(\"LAPD_Police_Stations.csv\")\n",
    "\n",
    "# past dataset has column name typo\n",
    "past_df = past_df.rename(columns={\"AREA \": \"AREA\"})\n",
    "\n",
    "# Both datasets use the same columns \n",
    "df = pd.concat([past_df, present_df])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crime dataset had quite a few columns that were unnecessary to us. Mainly these were columns containing codes that law enforcement used internally. However, these columns usually had a description column in the dataset so the code column was unnecessary for us. The only exception were Mocodes and Part 1-2 which are internally used codes but did not contain an associated description column. However after looking into what these codes meant, it was decided that they did not provide any use to us and were removed. In addition to this, we also removed Date Rptd (date crime was reported) since we only care about when the crime occured and not when it was reported. We also replaced the codes in Vict Descent with their actual descriptions that was provided in the site the dataset came from. Lastly, we converted DATE OCC to a datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping code columns since these are internal use and we don't get much \n",
    "# value from them given we have their description in a seperate column\n",
    "df = df.drop(columns=[\n",
    "    \"Crm Cd\", \"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \n",
    "    \"Crm Cd 4\", \"Premis Cd\", \"Weapon Used Cd\", \n",
    "    \"Mocodes\", \"Part 1-2\", \"Status\", \"Date Rptd\"\n",
    "    ])\n",
    "\n",
    "# Changed code to be readable description\n",
    "df[\"Vict Descent\"] = df[\"Vict Descent\"].replace({\n",
    "                            \"A\": \"Other Asian\", \n",
    "                            \"B\": \"Black\", \n",
    "                            \"C\": \"Chinese\", \n",
    "                            \"D\": \"Cambodian\", \n",
    "                            \"F\": \"Filipino\", \n",
    "                            \"G\": \"Guamanian\", \n",
    "                            \"H\": \"Hispanic/Latin/Mexican\", \n",
    "                            \"I\": \"American Indian/Alaskan Native\", \n",
    "                            \"J\": \"Japanese\", \n",
    "                            \"K\": \"Korean\", \n",
    "                            \"L\": \"Laotian\", \n",
    "                            \"O\": \"Other\", \n",
    "                            \"P\": \"Pacific Islander\", \n",
    "                            \"S\": \"Samoan\", \n",
    "                            \"U\": \"Hawaiian\", \n",
    "                            \"V\": \"Vietnamese\", \n",
    "                            \"W\": \"White\", \n",
    "                            \"X\": \"Unknown\", \n",
    "                            \"Z\": \"Asian Indian\",\n",
    "                        })\n",
    "\n",
    "# changed to DateTime\n",
    "df[\"DATE OCC\"] = pd.to_datetime(df['DATE OCC'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the geographic data was a similar process, but we left the datasets separate since it makes more sense.   \n",
    "\n",
    "For Dataset 1 we just renamed X and Y to Longitude. Latitude.  \n",
    "For Dataset 2 we dropped some columns that are repeated. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAPD_df = pd.read_csv(\"LAPD_Police_Stations.csv\")\n",
    "map_df = gpd.read_file('LAPD_Divisions.shp') \n",
    "\n",
    "# Renamed X,Y to Longitude, Latitude\n",
    "LAPD_df = LAPD_df.rename(columns={\n",
    "    \"X\": \"Longitude\", \n",
    "    \"Y\": \"Latitude\"\n",
    "    })\n",
    "\n",
    "# drop irrelevant columns\n",
    "map_df = map_df.drop(columns=['OBJECTID', 'SHAPE_Leng', 'SHAPE_Area'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During some initial EDA and plotting we found that there was data that was at (0, 0). These crimes did have information filled in for the lcoation column that we could have used to impute a Longitude, Latitude, but instead we opted to just drop them since there was only a few thousand of our million data points. \n",
    "\n",
    "Even after dropping them we found that many crimes took place outside of LA and the precinct boundaries. To avoid these affecting any location analysis and because it seemed largely random which precinct the crime was assigned to, we also decided to drop those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (10, 20))\n",
    "\n",
    "# plot the data before dropping\n",
    "map_df.boundary.plot(color='black', ax=ax[0])\n",
    "df.plot(ax=ax[0], x='LON', y='LAT', kind='scatter', c='red',  s=0.1)\n",
    "\n",
    "# drop the 0,0 data and show how much data was dropped\n",
    "before_size = df.shape[0]\n",
    "df = df.drop(df.loc[df['LAT'] < 1].index)\n",
    "df = df.drop(df.loc[df['LON'] > -1].index)\n",
    "after_size = df.shape[0]\n",
    "print('Size before removing (0,0) crimes: ', before_size)\n",
    "print('Size after removing (0,0) crimes: ', after_size)\n",
    "print('Dropped',before_size - after_size,'rows, which is',(before_size - after_size) / before_size,'% of the entire dataset')\n",
    "\n",
    "# plot the data after dropping\n",
    "map_df.boundary.plot(color='black', ax=ax[1])\n",
    "df.plot(ax=ax[1], x='LON', y='LAT', kind='scatter', c='AREA',  s=0.1, alpha=0.5, cmap='viridis')\n",
    "\n",
    "# drop data outside of LA precinct area\n",
    "\n",
    "before_size = df.shape[0]\n",
    "# arbitrarily chosen bounds for LA area\n",
    "df = df.loc[(df['LAT'] >= 33.7) & (df['LAT'] <= 34.37) & (df['LON'] >= -118.7) & (df['LON'] <= -118.15)]\n",
    "after_size = df.shape[0]\n",
    "print('Before: ', before_size)\n",
    "print('After: ', after_size)\n",
    "print('Dropped',before_size - after_size,'rows, which is',(before_size - after_size) / before_size,'% of the entire dataset')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot on the left shows the original data plotted. Clearly some of the points are extreme outliers and will mess up any geographic analysis. The plot on the right shows the data after just dropping the (0, 0) points. This time the area can be seen better, but there are still lots of crimes outside the zones. Additionally, we include a precinct color mapping this time and the points outside have a variety of colors instead of all corresponding to a single precinct or to the closest precinct. This means that there is not a clear pattern of which precinct is responsible for a crime outside the boundaries. Our final version of the map, with proper boundaries can be found later in our paper."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on in our EDA and analysis we do some additional operations that could be considered data cleaning. These were done for calculated fields or for specific plotting/analysis purposes. We left them in their own sections to make the code easier to follow and because our dataset at this point represents a cleaned dataset that others could use for their own purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geospatial EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move into our geospatial analysis. The first thing to look at is a map of the area we are looking at and where all the crimes were commited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize = (10, 6))\n",
    "map_df.boundary.plot(color='black', ax=ax)\n",
    "df.plot(ax=ax, x='LON', y='LAT', kind='scatter', c='AREA',  s=0.1, alpha=0.5, cmap='viridis')\n",
    "LAPD_df.plot(ax=ax, x='Longitude', y='Latitude', kind='scatter', s=5, c='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up a merged crime count table that has counts and area of precincts using df and map_df\n",
    "crime_counts = map_df.merge(df.groupby('AREA')[['DR_NO']].count().rename(columns={'DR_NO':'CRIME_COUNT'}), left_on='PREC', right_on='AREA')\n",
    "crime_counts = crime_counts.sort_values(by='CRIME_COUNT', ascending=False)\n",
    "\n",
    "crime_counts['CRIME_COUNT_VS_AREA'] = crime_counts['CRIME_COUNT'] / crime_counts['AREA']\n",
    "\n",
    "# adding an average\n",
    "meandict = dict(crime_counts.mean())\n",
    "meandict['APREC'] = '*AVERAGE'\n",
    "crime_counts = crime_counts.append(meandict, ignore_index=True)\n",
    "\n",
    "crime_counts['scaled_AREA'] = crime_counts['AREA'] / crime_counts['AREA'].max()\n",
    "crime_counts['scaled_CRIME_COUNT'] = crime_counts['CRIME_COUNT'] / crime_counts['CRIME_COUNT'].max()\n",
    "crime_counts['scaled_CRIME_COUNT_VS_AREA'] = crime_counts['CRIME_COUNT_VS_AREA'] / crime_counts['CRIME_COUNT_VS_AREA'].max()\n",
    "crime_counts.plot(\n",
    "    kind='barh', \n",
    "    x='APREC', \n",
    "    y=['scaled_CRIME_COUNT','scaled_AREA','scaled_CRIME_COUNT_VS_AREA'], \n",
    "    subplots=True, layout=(1,3), \n",
    "    figsize=(10, 5), \n",
    "    sharex=True, sharey=True,\n",
    "    legend=False,\n",
    "    title=['Number of Crimes Committed', 'Area of Precinct', 'Number of Crimes Committed/ Area']\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 3 plots show us lots of relevant information for our question. Firstly, not each precinct has the same amount of crimes commited. There is a difference of 70,000 crimes committed between the minimum and maximum (this graph is all max-scaled, due to issues plotting different tick lengths in subplots. Additionally the units for area are ambigious). Despite this range, a large amount of the precincts do have similar amounts of crimes committed within them, but the deviation on the edges \n",
    "\n",
    "On the other hand, the size of the precincts is all over the place. Based on these charts, we can see that Central has an average amount of crime compared to the other precincts, but it has one of the smallest areas. This leads it to have the largest Crime / Area value which is about 3 times more than the average.\n",
    "\n",
    "So are there better ways we could arrange the police stations? Are there other factors we should take into consider for police station placement?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD STUFF STARTS HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if Longitude and Latitude make sense for LA area. (Originally included 0,0 values, now seems to include the expected area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(columns=['Column','Min', 'Mean', 'Median', 'Max'], data=[\n",
    "    ['LAT', df['LAT'].min(), df['LAT'].mean(), df['LAT'].median(), df['LAT'].max()],\n",
    "    ['LON', df['LON'].min(), df['LON'].mean(), df['LON'].median(), df['LON'].max()]\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after removing the 0,0 longitude latitude crimes, many crimes happen outside of the zone of any of the precincts (see the plot below). Since we plan to work with location data and clustering, these outliers will cause problems for our analysis. So we removed even more of the data to hone in on the area we truly care about, which is within the precinct boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = gpd.read_file('LAPD_Divisions.shp')\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (20, 12))\n",
    "map_df.boundary.plot(color='black', ax=ax)\n",
    "df.plot(ax=ax, x='LON', y='LAT', kind='scatter', c='AREA',  s=0.1, cmap='viridis')\n",
    "LAPD_df.plot(ax=ax, x='Longitude', y='Latitude', kind='scatter', s=5, c='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code snippet that could be useful later for determining better bounds\n",
    "# map_df['geometry'].astype(str)\\\n",
    "#     .str[8:]\\\n",
    "#     .str.replace('(', '')\\\n",
    "#     .str.replace(')', '')\\\n",
    "#     .str.replace(',', '')\\\n",
    "#     .str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_size = df.shape[0]\n",
    "\n",
    "# arbitrarily chosen bounds for LA area\n",
    "df = df.drop(df.loc[(df['LAT'] <= 33.7) & (df['LAT'] >= 34.37) & (df['LON'] <= -118.7) & (df['LON'] >= -118.15)].index)\n",
    "\n",
    "after_size = df.shape[0]\n",
    "print('Before: ', before_size)\n",
    "print('After: ', after_size)\n",
    "print('Dropped',before_size - after_size,'rows, which is',(before_size - after_size) / before_size,'% of the entire dataset')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now our dataset just contains the areas within the precinct and not a large area around them. This will help with our clustering and our analysis by removing outlier datapoints. These points outside the precinct boundaries seem randomly assigned to precincts or at least use a pattern that was not noted.\n",
    "\n",
    "With this all finished we can plot the whole area again. Additionally we can add each of the latitudes and longitudes from the entire crime set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = gpd.read_file('LAPD_Divisions.shp')\n",
    "df_plot = df.loc[(df['LAT'] >= 33.7) & (df['LAT'] <= 34.37) & (df['LON'] >= -118.7) & (df['LON'] <= -118.15)]\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (20, 12))\n",
    "map_df.boundary.plot(color='black', ax=ax)\n",
    "df_plot.plot(ax=ax, x='LON', y='LAT', kind='scatter', c='AREA',  s=0.1, alpha=0.5, cmap='viridis')\n",
    "LAPD_df.plot(ax=ax, x='Longitude', y='Latitude', kind='scatter', s=5, c='black')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the crime distribution is largely containted within the precincts. The black dots are the police station locations themselves. A good thing to take note of is that the police stations are not centered in their respective zones. While some are roughly in the middle, there are also some on the edge of their zones. This is interesting since for effective coverage we would expect them to be centered so they can optimally cover their area. This will likely affect our analysis since our calculated locations will be centered on the crime around them and thus would likely be centered in their zones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime Counts in Relation to Precinct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our research question involves location information we want to focus our explorations around that. Specifically we would like to see if there are similar amounts of crimes commited in each precinct, if each precinct has similar areas, if each precinct has similar coverage.\n",
    "\n",
    "First let's look at the number of crimes in each precinct.\n",
    "\n",
    "One thing that we would be interested in knowing is if there is an equal distribution of crimes between police stations. From this we can see that there is a difference between how many cases each station has handled. This could either mean that some police stations are responsible for a larger area or there are more crimes happening in the areas those stations are covering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up a merged crime count table that has counts and area of precincts using df and map_df\n",
    "crime_counts = map_df.merge(df.groupby('AREA')[['DR_NO']].count().rename(columns={'DR_NO':'CRIME_COUNT'}), left_on='PREC', right_on='AREA')\n",
    "crime_counts = crime_counts.sort_values(by='CRIME_COUNT', ascending=False)\n",
    "crime_counts.plot(kind='barh', x='APREC', y='CRIME_COUNT')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are a few with less and a few with more it seems that there are similar amounts of crime commited in each precint.\n",
    "\n",
    "But based on our map we know that the precint's are not all the same size, so can the differences in numbers of crime commited be related to size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_counts['CRIME_COUNT_VS_AREA'] = crime_counts['CRIME_COUNT'] / crime_counts['AREA']\n",
    "\n",
    "crime_counts['scaled_AREA'] = crime_counts['AREA'] / crime_counts['AREA'].max()\n",
    "crime_counts['scaled_CRIME_COUNT'] = crime_counts['CRIME_COUNT'] / crime_counts['CRIME_COUNT'].max()\n",
    "crime_counts['scaled_CRIME_COUNT_VS_AREA'] = crime_counts['CRIME_COUNT_VS_AREA'] / crime_counts['CRIME_COUNT_VS_AREA'].max()\n",
    "crime_counts.plot(\n",
    "    kind='barh', \n",
    "    x='APREC', \n",
    "    y=['scaled_CRIME_COUNT','scaled_AREA','scaled_CRIME_COUNT_VS_AREA'], \n",
    "    subplots=True, layout=(1,3), \n",
    "    figsize=(10, 5), \n",
    "    sharex=True, sharey=True,\n",
    "    legend=False,\n",
    "    title=['Number of Crimes Committed', 'Area of Precinct', 'Number of Crimes Committed/ Area']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the values have been scaled\n",
    "The first bar chart is just the number of crimes commited in each area.\n",
    "The second is the area of each precint.\n",
    "The last bar chart is the number of crimes / the area of the precinct.\n",
    "Since the axis are aligned each corresponds to the same area. So despite having an average number of crimes commited, the Central precinct has a very small area compared to the others and gets a higher value on the right bar chart. Since the bars on the right are not all the same size, then that means there is a disparity between the size of a precint and the number of crimes commited there."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD STUFF ENDS HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This moves us into our first analysis for our project. Since the size of each precinct and the amount of crime commited isn't balanced, we attempted to see if there are better boundaries and locations for the police stations.\n",
    "\n",
    "We did this by using  K-Means Clustering. The idea was that we could find new locations for police centers and precinct boundaries mathmatically by taking into account the number of crimes in each area. We would expect these to more effectively spread the crimes among police stations, but also to not be too different from the current locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=21)\n",
    "kmeans.fit(df[[\"LON\", \"LAT\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_df = pd.DataFrame(kmeans.cluster_centers_, columns=['Longitude', 'Latitude'])\n",
    "\n",
    "map_df = gpd.read_file('LAPD_Divisions.shp')\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (18, 8))\n",
    "map_df.boundary.plot(color='black', ax=ax)\n",
    "\n",
    "\n",
    "# labeling each crime to a cluster\n",
    "df[\"cluster\"] = kmeans.predict(df[[\"LON\", \"LAT\"]])\n",
    "df.plot(ax=ax, x='LON', y='LAT', kind='scatter', c='cluster',  s=0.1, alpha=0.5, cmap='viridis')\n",
    "\n",
    "\n",
    "LAPD_df.plot(ax=ax, x='Longitude', y='Latitude', kind='scatter', s=10, c='orange')\n",
    "centers_df.plot(ax=ax, x='Longitude', y='Latitude', kind='scatter', s=10, c='blue') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = [21, 10, 40]\n",
    "for n in range(len(num_clusters)):\n",
    "    # calculate k-means with n clusters\n",
    "    kmeans = KMeans(n_clusters = num_clusters[n])\n",
    "    kmeans.fit(df[[\"LON\", \"LAT\"]])\n",
    "\n",
    "    # make a df of the centers\n",
    "    centers_df = pd.DataFrame(kmeans.cluster_centers_, columns=['Longitude', 'Latitude'])\n",
    "\n",
    "    # add a cluster label to each crime\n",
    "    df[\"cluster\"] = kmeans.predict(df[[\"LON\", \"LAT\"]])\n",
    "\n",
    "    # plot the precinct shapes, plot the cluster labeled crimes, plot the centers\n",
    "    # map_df.boundary.plot(color='black', ax=ax[0][n])\n",
    "    df.plot(ax=ax[0][n+1], x='LON', y='LAT', kind='scatter', c='cluster',  s=0.1, alpha=0.5, cmap='viridis')\n",
    "    centers_df.plot(ax=ax[0][n+1], x='Longitude', y='Latitude', kind='scatter', s=10, c='black') \n",
    "\n",
    "    # plot a bar chart of number of crimes per cluster\n",
    "    df[\"cluster\"].value_counts().plot(kind=\"barh\", ax=ax[1][n+1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot has a lot to unpack so let's go through each part of it.  \n",
    "The top row contains maps just like our earlier one, with each of the points being a crime and the color corresponding to the precinct/cluster it belongs to. The bottom row contains bar charts that show the number of crimes in each precinct/cluster.\n",
    "\n",
    "Each map and bar chart are paired with each other. We first plotted our results of having 21 clusters, which would be the same number of precincts as the city currently has. These centers are close to their originals, but there are some slight movements that suggest the current locations are not optimal clusters. Despite that, we actually have a different distribution of crimes per precinct and it is less balanced than the original.\n",
    "\n",
    "With that in mind we tried having half as many precincts and twice as many precincts. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArcGIS Maximize Coverage Method\n",
    "Another approach to analysis we performed is using ArcGIS.\n",
    "\n",
    "ArcGIS offers algorithms to chose the best locations for a certain goal, the \"Choose Best Facilities\" allows you to choose the best locations for facilities. The tool allocates locations with demand for the facilities in a way that satisfies the specified goal.\n",
    "\n",
    "Our goal is to see if there could be better locations to place police stations so that crimes are evenly more distributed among stations. This algorithm maximizes the amount of demand covered within a specific time or distance of the facilities, in our case we are minimizing the driving time required from police stations to crimes in the area. \n",
    "\n",
    "Demand in our case is the amount of crime, and each demand location is where a crime occurs. For the purpose of simplifying the solution, we will pick an arbitrary type of crime and focus only on crimes that are labeled as \"Attempted Robbery\", and we will be using 2020-Present dataset. This goal chooses facilities such that the maximum amount of demand is allocated, with all the demand from each demand location allocated to the single facility closest to it.\n",
    "\n",
    "In theory we should get the best places to place these stations geographically, but let's see how it does for distributing crimes evenly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset for candidate police stations, downloaded from Google Drive\n",
    "new_max_stations = pd.read_csv('new_maximized_stations.csv')\n",
    "new_max_stations = new_max_stations[new_max_stations['Facility Type'] == \"Chosen\"] #Filter to the chosen new stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New locations of police stations generated by the Maximize Coverage method\n",
    "\n",
    "![new locations](images/new_stations.png \"New Police Stations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly when we set the amount of new locations = 21 (The same number of current police stations and number of precincts) the algorithm suggested that multiple police stations be placed on certain precincts and none at all in some of the precincts. This finding suggests that maybe there needs to be reformation in the policing system to maximize coverage of crimes. This could mean that in high demand areas there are not enough police stations to cover for the amount of crime that happens in the area, and in the low demand areas, the amount of policing/stations could potentially be reduced and have those resources be allocated somewhere with a higher crime rate. However, this was done on only one type of crime \"Attempted Robbery\" and the answer can't be generalized to all types of crime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robbery_locations = pd.read_csv('crime_demand_points.csv')\n",
    "\n",
    "#Filter the crimes that are selected for the maximizing demand algorithm\n",
    "list_facility_ids = list(new_max_stations['OBJECTID_1'].unique())\n",
    "robbery_locations = robbery_locations[robbery_locations['Assigned Facility ID'].isin(list_facility_ids)]\n",
    "\n",
    "#Plot the counts of crimes for the new assigned police station locations\n",
    "robbery_locations['Assigned Facility ID'].value_counts().plot(kind='barh') #The assigned new location for that crime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime to Police Station Distance Analysis\n",
    "Because we weren't able to efficiently place police stations such that it evenly distribute crimes to each station with our 2 methods, our next approach is to visualize how close crimes happen to police stations and how much crime happens near a police station. Performing this analysis will give us answer to confirm or deny our hypothesis which was that 'We believe that less crime will happen closer to police stations' since police stations are referred to a safe area and would logically deter crime."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating crimes near police station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging crimes with LA police station. This is to get location of crime with location of the associated police station\n",
    "df_merged = df_plot.merge(LAPD_df, left_on = \"AREA\", right_on = \"PREC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance calculator between longitude latitude points\n",
    "# code got and modified from https://stackoverflow.com/questions/29545704/fast-haversine-approximation-python-pandas/29546836#29546836 \n",
    "\n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    \n",
    "    miles = km * 0.6214 \n",
    "    return miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating distance of crime to their respective police stations\n",
    "df_merged[\"distance\"] = haversine_np(df_merged[\"LON\"], df_merged[\"LAT\"], df_merged[\"Longitude\"], df_merged[\"Latitude\"])\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance is in miles, considering crimes that happen within 1 mile of police stations to be close\n",
    "df_merged[\"near_police\"] = df_merged[\"distance\"] < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of crimes that were near police station\n",
    "df_merged[\"near_police\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of crimes near and away from their respective police station\n",
    "fig, ax = plt.subplots(1, figsize = (10, 8))\n",
    "df_merged.groupby(\"AREA NAME\")[\"near_police\"].value_counts().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting column to int so that it can be plotted\n",
    "df_merged[\"near_police\"] = df_merged[\"near_police\"].astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (18, 8))\n",
    "map_df.boundary.plot(color='black', ax=ax)\n",
    "\n",
    "\n",
    "df_merged.plot(ax=ax, x='LON', y='LAT', kind='scatter', c='near_police',  s=0.1, alpha=0.5, cmap='viridis')\n",
    "\n",
    "\n",
    "LAPD_df.plot(ax=ax, x='Longitude', y='Latitude', kind='scatter', s=10, c='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD STUFF STARTS HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kmeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering the locations of where crimes occur will give us a general map of how the precints should be divided. In addition, the centers of the clusters would be the optimal locations to put police stations. In this case, we chose to use k-means clustering and we chose the number of clusters to be 21 since there are 21 police stations in LA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=21)\n",
    "kmeans.fit(df[[\"LON\", \"LAT\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting K-means with the location data, we can then plot everything on a map of LA. In addition, we can also plot which cluster each point is part of which would relate to which station they belong to as well as mapping out the precinct lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_df = pd.DataFrame(kmeans.cluster_centers_, columns=['Longitude', 'Latitude'])\n",
    "\n",
    "map_df = gpd.read_file('LAPD_Divisions.shp')\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (18, 8))\n",
    "map_df.boundary.plot(color='black', ax=ax)\n",
    "\n",
    "\n",
    "# labeling each crime to a cluster\n",
    "df[\"cluster\"] = kmeans.predict(df[[\"LON\", \"LAT\"]])\n",
    "df.plot(ax=ax, x='LON', y='LAT', kind='scatter', c='cluster',  s=0.1, alpha=0.5, cmap='viridis')\n",
    "\n",
    "\n",
    "LAPD_df.plot(ax=ax, x='Longitude', y='Latitude', kind='scatter', s=10, c='orange')\n",
    "centers_df.plot(ax=ax, x='Longitude', y='Latitude', kind='scatter', s=10, c='blue') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph shows two random dots and does not have a map of LA. This was due to some points being labeled as 0,0 which is why k-means made them into a cluster. To ammend this, we have to filter the coordinates so that they are mapped to the area of LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.loc[(df['LAT'] >= 33.7) & (df['LAT'] <= 34.37) & (df['LON'] >= -118.7) & (df['LON'] <= -118.15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=21)\n",
    "kmeans.fit(df_plot[[\"LON\", \"LAT\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_df = pd.DataFrame(kmeans.cluster_centers_, columns=['Longitude', 'Latitude'])\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (18, 8))\n",
    "map_df.boundary.plot(color='black', ax=ax)\n",
    "\n",
    "\n",
    "\n",
    "df_plot[\"cluster\"] = kmeans.predict(df_plot[[\"LON\", \"LAT\"]])\n",
    "df_plot.plot(ax=ax, x='LON', y='LAT', kind='scatter', c='cluster',  s=0.1, alpha=0.5, cmap='viridis')\n",
    "\n",
    "\n",
    "LAPD_df.plot(ax=ax, x='Longitude', y='Latitude', kind='scatter', s=10, c='orange')\n",
    "centers_df.plot(ax=ax, x='Longitude', y='Latitude', kind='scatter', s=10, c='blue') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some centers from k-means are actually fairly close to actual police stations. In addition we can see borders of how each precint should be mapped based on k-means clustering."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check if this has made the distribution of crime per station more even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot[\"cluster\"].value_counts().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot[\"AREA NAME\"].value_counts().plot(kind=\"barh\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it seems that k-means has actually made the distribution worse as there are now larger differences between stations. K-means did not give us centers that would equally distribute crimes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another idea to try is maybe there are too much police stations in LA. What we can do is reduce the number of clusters k-means has to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_la_crime(num_clusters):\n",
    "    kmeans = KMeans(n_clusters = num_clusters)\n",
    "    kmeans.fit(df_plot[[\"LON\", \"LAT\"]])\n",
    "\n",
    "    centers_df = pd.DataFrame(kmeans.cluster_centers_, columns=['Longitude', 'Latitude'])\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize = (18, 8))\n",
    "    map_df.boundary.plot(color='black', ax=ax)\n",
    "\n",
    "\n",
    "\n",
    "    df_plot[\"cluster\"] = kmeans.predict(df_plot[[\"LON\", \"LAT\"]])\n",
    "    df_plot.plot(ax=ax, x='LON', y='LAT', kind='scatter', c='cluster',  s=0.1, alpha=0.5, cmap='viridis')\n",
    "\n",
    "\n",
    "    LAPD_df.plot(ax=ax, x='Longitude', y='Latitude', kind='scatter', s=10, c='orange')\n",
    "    centers_df.plot(ax=ax, x='Longitude', y='Latitude', kind='scatter', s=10, c='blue') \n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "    df_plot[\"cluster\"].value_counts().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decreasing centers \n",
    "cluster_la_crime(5)\n",
    "cluster_la_crime(10)\n",
    "cluster_la_crime(15)\n",
    "\n",
    "# increasing centers\n",
    "cluster_la_crime(30)\n",
    "cluster_la_crime(40)\n",
    "cluster_la_crime(50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs, it seems that k-means will not give equal distributions of crime. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD STUFF ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main bias issues in our dataset, is that it only contains reported crimes. Since crimes must be reported by police officers, they inherently are linked to the prescence of a nearby police station. While we would expect this to increase volume of crimes reported nearby police stations, our hypothesis goes against that expectation by assuming that the deterence of a police station will outweight this effect. In order to address this we will carefully word our analysis descriptions and take this into account in our conclusions. \n",
    "\n",
    "Another potential bias in our dataset is that since it is only covering the area of Los Angeles and might not be representative of crime in general for the rest of the state/nation; furthermore, our data could also have an imbalanced proportion of populations due to the nature of policing and crime. In particular, the overpolicing of low income and minority areas could skew our analyses results and present problematic solutions. To tackle this problem, we will carefully analyze for these patterns in our dataset and point them out if/when they arise, as well as preface our solutions with a warning.\n",
    "\n",
    "Privacy should be well protected because the records do not include the names of the victim or culprit. The only thing that links the crime to the people involved is the Division of Records Number serving as an ID of each crime. However only the Los Angeles Police Department has access to the records. In addition to this, the Los Angeles Police Department specified in the description that they round the addresses to the nearest hundred blocks to protect privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your discussion information here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Specify who in your group worked on which parts of the project.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
